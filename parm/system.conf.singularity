## This is the system-specific configuration file for the AWS
[config]
## Project disk area
disk_project=hwrf
## Project hpss tape area
tape_project=None
## CPU account name for submitting jobs to the batch system.
cpu_account=None
## Archive path
#archive=hpss:/NCEPDEV/{tape_project}/5year/{ENV[USER]}/{SUBEXPT}/{out_prefix}.tar
## Specify input sources for HISTORY mode.
input_sources=aws_sources_{GFSVER}
## Specify the DataCatalog for FORECAST mode runs.
fcst_catalog=aws_fcst_{GFSVER}

[hafsdata]
inputroot=/scratch1/NCEPDEV/hwrf/noscrub/hafs-input/hafsdata_{GFSVER}

[aws_fcst_PROD2019]
inputroot=/scratch1/NCEPDEV/hwrf/noscrub/hafs-input/COMGFSv16

[dir]
## Non-scrubbed directory for track files, etc.  Make sure you edit this.
CDNOSCRUB=/opt/HAFS_OUTPUT/noscrub/hafstrak
DOCNdir=/opt/HAFS_OUTPUT/noscrub/DOCN
DATMdir=/opt/HAFS_OUTPUT/noscrub/DATM
## Save directory.  Make sure you edit this.
CDSAVE=/opt
## Scrubbed directory for large work files.  Make sure you edit this.
CDSCRUB=/opt/HAFS_OUTPUT/scrub
## Syndat directory for finding which cycles to run
syndat=/opt/HAFS_INPUT
## Input GFS data directory
COMgfs=/opt/HAFS_INPUT
COMINgfs={COMgfs}
COMrtofs=/opt/HAFS_INPUT
COMINrtofs={COMrtofs}
## A-Deck directory for graphics
ADECKhafs=/opt/HAFS_INPUT/abdeck/aid
## B-Deck directory for graphics
BDECKhafs=/opt/HAFS_INPUT/abdeck/btk

[holdvars]
WHERE_AM_I=aws    ;; Which cluster?  (For setting up environment.)
WHICH_JET=none     ;; Which part of Jet are we on?  None; we are not on Jet.

[forecast]
glob_layoutx=8
glob_layouty=10
layoutx=40
layouty=30
write_groups=1
write_tasks_per_group=140

[rocotostr]
FORECAST_RESOURCES=FORECAST_RESOURCES_regional_{forecast/layoutx}x{forecast/layouty}io{forecast/write_groups}x{forecast/write_tasks_per_group}_omp2
